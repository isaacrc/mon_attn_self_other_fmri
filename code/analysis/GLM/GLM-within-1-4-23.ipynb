{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "square-tokyo",
   "metadata": {},
   "source": [
    "# Within analysis GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-print",
   "metadata": {},
   "source": [
    "This script performs within analysis including:\n",
    "- SM win 3, win 2, win 1 minus win 0\n",
    "- SC win 3, win 2, win 1 minus win 0\n",
    "- OM win 3, win 2, win 1 minus win 0\n",
    "- OC win 3, win 2, win 1 minus win 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "veterinary-protein",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "from nilearn.input_data import NiftiMasker , MultiNiftiMasker, NiftiLabelsMasker\n",
    "import nilearn as nil\n",
    "import numpy as np \n",
    "import os\n",
    "import os.path\n",
    "import scipy.io\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.masking import compute_epi_mask\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "import sys  \n",
    "import random\n",
    "# import logging\n",
    "\n",
    "import deepdish as dd\n",
    "import numpy as np\n",
    "\n",
    "import brainiak.eventseg.event\n",
    "import nibabel as nib\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.image import math_img\n",
    "\n",
    "\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, zscore, pearsonr\n",
    "from scipy.signal import gaussian, convolve\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns \n",
    "\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "from brainiak import image, io\n",
    "from scipy.stats import stats\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from brainiak import image, io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import pandas as pd\n",
    "# Import machine learning libraries\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold, f_classif, SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import sem\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import statistics\n",
    "# Visualize it as an ROI\n",
    "from nilearn.plotting import plot_roi\n",
    "#plot_roi(x)\n",
    "from nilearn.image import concat_imgs, resample_img, mean_img\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn import datasets, plotting\n",
    "from nilearn.input_data import NiftiSpheresMasker\n",
    "\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn.image import concat_imgs, resample_img, mean_img,index_img\n",
    "from nilearn import image\n",
    "from nilearn import masking\n",
    "from nilearn.plotting import view_img\n",
    "from nilearn.image import resample_to_img\n",
    "from scipy.spatial.distance import squareform\n",
    "# Visualize it as an ROI\n",
    "from nilearn.plotting import plot_roi\n",
    "import statsmodels.stats.multitest as st\n",
    "from nilearn import connectome\n",
    "from nilearn import image\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from nilearn import input_data\n",
    "from nilearn.plotting import plot_glass_brain\n",
    "from nilearn.masking import apply_mask\n",
    "import random\n",
    "from nilearn.image import concat_imgs, resample_img, mean_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "international-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import label_lists, find_cond_index, load_epi_data, load_roi_mask,intersect_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "visible-mauritius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 5\n",
    "%matplotlib inline\n",
    "sns.set(style = 'white', context='talk', font_scale=1, rc={\"lines.linewidth\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-logging",
   "metadata": {},
   "source": [
    "# Custom Study Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "creative-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnd_indices(sub,behav_p):\n",
    "    behav = pd.read_csv(os.path.join(behav_p, '%s_behav_cleaned.csv') % (sub))\n",
    "    # Define the column in behav to be used for creating labels # \n",
    "    label = behav.iloc[:,1]\n",
    "    # Create an array of labels [1] AND the order in which runs occured [0]#\n",
    "    sub_ses_labels = label_lists(label, 200)\n",
    "    ## Find run sequence, extraction condition indexes from behav data ## \n",
    "    return find_cond_index(sub_ses_labels[0])\n",
    "def org_bdata(unsort_bdata, run_indexes, cond_a, cond_b): \n",
    "    \"\"\"\n",
    "    organize two runs for concatenation\n",
    "    Two runs of cond_a, then two runs of cond_b\n",
    "    \n",
    "    \"\"\"\n",
    "    bold_data = []\n",
    "    a = [unsort_bdata[run_indexes[cond_a][0]], unsort_bdata[run_indexes[cond_a][1]]]\n",
    "    b = [unsort_bdata[run_indexes[cond_b][0]], unsort_bdata[run_indexes[cond_b][1]]]\n",
    "    print(\"returning\", cond_a, cond_b)\n",
    "    return np.asarray(a), np.asarray(b)\n",
    "\n",
    "def find_cond_index(sub_ses_labels):\n",
    "    \"\"\"\n",
    "    For the array of ordered run names (i.e.'Re', 'SM',) find the two indexes per condition\n",
    "    \"\"\" \n",
    "    lab_inx = []\n",
    "\n",
    "    a = []\n",
    "    b = []\n",
    "    c = []\n",
    "    d = []\n",
    "    e = []\n",
    "\n",
    "    for i in enumerate(sub_ses_labels):\n",
    "        if i[1] == \"SM\":\n",
    "            # append the index according to where it appeared in the array\n",
    "            a.append(i[0])\n",
    "        if i[1] == \"SC\":\n",
    "            b.append(i[0])\n",
    "        if i[1] == \"OM\":\n",
    "            c.append(i[0])\n",
    "        if i[1] == \"OC\":\n",
    "            d.append(i[0])\n",
    "\n",
    "    # Create a dictionary where each key contains the appropriate indexes\n",
    "    lab_indic = {\n",
    "        'SM' : a,\n",
    "        'SC' : b,\n",
    "        'OM' : c,\n",
    "        'OC' : d,\n",
    "        'RE' : [0,9]\n",
    "    }\n",
    "    return lab_indic \n",
    "    #np.vstack(lab_inx, [\"SM\", \"SC\", \"OM\", \"OC\"])\n",
    "    \n",
    "def load_confounds(cond_list, sub_list,behav_p,confounds):\n",
    "    \"\"\"\n",
    "    args: \n",
    "        cond_list: list of conditions (cond_list=np.array(['SM','SC']))\n",
    "        sub_list: subjects to extract confounds for\n",
    "        behav_p: path to the behavioral data\n",
    "        confounds: path to the confound data\n",
    "    returns:\n",
    "        nested dictionary in the form of: conf_sub[sub][cond][img_ind]\n",
    "        where img_index is the first or second run\n",
    "    \"\"\"\n",
    "    # Confound files\n",
    "\n",
    "    conf_sub = {}\n",
    "    for sub in sub_list:\n",
    "        conf_cond = {}\n",
    "        for cond in cond_list:\n",
    "            confs = []\n",
    "            lab_indic = fnd_indices(sub, behav_p)\n",
    "            confs.append(np.asarray(pd.read_csv(os.path.join(confounds + sub + \"/func/\", \n",
    "                                                             '%s_ses-01_task-Attn_run-%s_desc-model_timeseries.csv') % (sub, lab_indic[cond][0])))[4:,:])\n",
    "            confs.append(np.asarray(pd.read_csv(os.path.join(confounds + sub + \"/func/\",\n",
    "                                                             '%s_ses-01_task-Attn_run-%s_desc-model_timeseries.csv') % (sub, lab_indic[cond][1])))[4:,:])\n",
    "            conf_cond[cond] = confs\n",
    "        conf_sub[sub] = conf_cond\n",
    "    return conf_sub\n",
    "\n",
    "\n",
    "def load_2conds_runs_fmri(sub,behav_p,cond_a,cond_b, run_dic, suffix=\"_205_noproc.npy\"):\n",
    "    \"\"\"\n",
    "    read in target conditions + subject info\n",
    "    output: 2 runs of condition A, as they were presented, then two runs of condition B\n",
    "    \"\"\"\n",
    "    cats = list(np.load(load_fmri + sub + suffix, allow_pickle =True)) \n",
    "    # Find run labels from behavioral data\n",
    "    lab_indic = fnd_indices(sub, behav_p)\n",
    "    # Organize and concatenate bold data\n",
    "    a, b = org_bdata(cats, lab_indic, cond_a, cond_b)\n",
    "    # Get the indices of the runs to include #\n",
    "    return list(a[run_dic[sub][cond_a]]), list(b[run_dic[sub][cond_b]])\n",
    "\n",
    "\n",
    "def create_event_list(sub, bpress, cond, run_dic, base_onset,comp_onset_list,stim_dur):\n",
    "    \"\"\"\n",
    "    this function reads in a condition for each sub\n",
    "    and returns the corresponding b4 + after events\n",
    "    \n",
    "    sub: subject number\n",
    "    bpress: array of button press onset times\n",
    "    cond: which condition do you want to create event dataframe fore\n",
    "    \"\"\"\n",
    "    all_tims = []\n",
    "    events = {}\n",
    "    # Convert to array #\n",
    "    bpress_arr = np.asarray(bpress[sub][cond])\n",
    "    # Select runs to include according to run_dic, append\n",
    "    all_tims = all_tims + list(bpress_arr[run_dic[sub][cond]])\n",
    "    # how much to shift from button press onset\n",
    "\n",
    "\n",
    "    # events will take  the form of a dictionary of Dataframes, one per run! \n",
    "    for run in range(len(all_tims)):\n",
    "        cond_labs = []\n",
    "        duration = []\n",
    "        onsets = []\n",
    "        window_list = []\n",
    "        # Do base first, then iterate on windows # \n",
    "        cond_labs = cond_labs + ['win0']* len(all_tims[run])\n",
    "        duration = duration + [stim_dur] * len(all_tims[run])\n",
    "        # onsets \n",
    "        onsets_unshft_prs = list(all_tims[run].astype(float))\n",
    "        onsets = onsets + [y + base_onset for y in onsets_unshft_prs]\n",
    "\n",
    "        for idx, comp_onset in enumerate(comp_onset_list):\n",
    "            # Create a list of 'press' for how many presses there were for each run\n",
    "            # label evaluates to 'win1'\n",
    "            cond_labs = cond_labs + ['win'+str(idx+1)]* len(all_tims[run])\n",
    "\n",
    "            # How long does the button event event last? one tr, so 1.5\n",
    "            duration = duration + [stim_dur] * len(all_tims[run])\n",
    "\n",
    "            # these are the corresponding onset times\n",
    "            onsets = onsets +  [y + comp_onset for y in onsets_unshft_prs]\n",
    "            # how many windows? add to list\n",
    "            window_list.append('win'+str(idx+1))\n",
    "        # Define the events object\n",
    "        events_ = pd.DataFrame(\n",
    "            {'onset': onsets, 'trial_type': cond_labs, 'duration': duration})\n",
    "        # remove the rest condition and insert into the dictionary\n",
    "        events[run] = events_\n",
    "    return events, window_list\n",
    "def create_event_list_rest(sub, bpress, cond, cond_alt, run_dic, base_onset,comp_onset_list,stim_dur):\n",
    "    \"\"\"\n",
    "    this function reads in a condition for each sub\n",
    "    and returns the corresponding b4 + after events\n",
    "    \n",
    "    sub: subject number\n",
    "    bpress: array of button press onset times\n",
    "    cond: which condition do you want to create event dataframe fore\n",
    "    \"\"\"\n",
    "    all_tims = []\n",
    "    events = {}\n",
    "    # Convert alternate bpress to array for ALTERNATE CONDITION #\n",
    "    bpress_arr = np.asarray(bpress[sub][cond_alt])\n",
    "    # Select runs to include according to run_dic, append\n",
    "    # * include correct runs of rest - those that were'nt excluded due to hm  \n",
    "    all_tims = all_tims + list(bpress_arr[run_dic[sub]['RE']])\n",
    "    # how much to shift from button press onset\n",
    "    \n",
    "    ## create fake bpress for missing data \n",
    "    ## if only one run for SM, then we still need button press data for two runs of RE ## \n",
    "    ## only add a second run if both runs of RE are included [second condition]\n",
    "    if len(all_tims) <2 and len(run_dic[sub]['RE']) >1:\n",
    "        all_tims = list(all_tims[0], all_tims[0])\n",
    "        \n",
    "\n",
    "    # events will take  the form of a dictionary of Dataframes, one per run! \n",
    "    for run in range(len(all_tims)):\n",
    "        cond_labs = []\n",
    "        duration = []\n",
    "        onsets = []\n",
    "        window_list = []\n",
    "        # Do base first, then iterate on windows # \n",
    "        cond_labs = cond_labs + ['win0']* len(all_tims[run])\n",
    "        duration = duration + [stim_dur] * len(all_tims[run])\n",
    "        # onsets \n",
    "        onsets_unshft_prs = list(all_tims[run].astype(float))\n",
    "        onsets = onsets + [y + base_onset for y in onsets_unshft_prs]\n",
    "\n",
    "        for idx, comp_onset in enumerate(comp_onset_list):\n",
    "            # Create a list of 'press' for how many presses there were for each run\n",
    "            # label evaluates to 'win1'\n",
    "            cond_labs = cond_labs + ['win'+str(idx+1)]* len(all_tims[run])\n",
    "\n",
    "            # How long does the button event event last? one tr, so 1.5\n",
    "            duration = duration + [stim_dur] * len(all_tims[run])\n",
    "\n",
    "            # these are the corresponding onset times\n",
    "            onsets = onsets +  [y + comp_onset for y in onsets_unshft_prs]\n",
    "            # how many windows? add to list\n",
    "            window_list.append('win'+str(idx+1))\n",
    "        # Define the events object\n",
    "        events_ = pd.DataFrame(\n",
    "            {'onset': onsets, 'trial_type': cond_labs, 'duration': duration})\n",
    "        # remove the rest condition and insert into the dictionary\n",
    "        events[run] = events_\n",
    "    return events, window_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-shame",
   "metadata": {},
   "source": [
    "# Define Static VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conventional-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/bids' # where the fMRI data is downloaded\n",
    "rois_dir = ... # not specified \n",
    "behav_p = '../behavioral/stim_list'\n",
    "load_bpress = \"../behavioral/\"\n",
    "load_fmri = '...' #location of preprocessed data output from preproc scripts\n",
    "out_dir = \"../../data/output\" # where to save the directory\n",
    "confounds_dir = '../behavioral_data/confound_info/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-bottom",
   "metadata": {},
   "source": [
    "# Sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legal-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = [\"sub-000\",\"sub-001\",\"sub-002\",\"sub-003\",\"sub-004\",\"sub-005\",\"sub-006\",\"sub-007\",\"sub-008\",\"sub-009\",\n",
    "            \"sub-010\",\"sub-011\",\"sub-012\",\"sub-013\",\"sub-014\",\"sub-015\", \"sub-016\",\"sub-017\", \n",
    "            \"sub-018\", \"sub-019\", \"sub-020\",\"sub-021\",'sub-022','sub-023','sub-024','sub-025','sub-026','sub-027']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-rouge",
   "metadata": {},
   "source": [
    "# Analysis variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "harmful-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '../../data/outputn28_p3_betas_4fhwm_hp001p25_shaefGM_excOvlp'\n"
     ]
    }
   ],
   "source": [
    "## Set ewwing ##\n",
    "# ** Only need to change inputs below!\n",
    "hm_thresh = str(3)\n",
    "prefix = 'within_between'\n",
    "prefix1= 'within'\n",
    "sav_dir = 'n28_p'+hm_thresh+'_betas_4fhwm_hp001p25_shaefGM_excOvlp'\n",
    "\n",
    "# vars of interest\n",
    "base_onset = -6\n",
    "# how many windows and what is the onset start time\n",
    "# we're now centering on the TR in which the bpress occured - onset of win 1\n",
    "# -3-3,-3+3,-3+6\n",
    "comp_onset_list = [-3,0,3]\n",
    "stim_dur = 3\n",
    "\n",
    "\n",
    "# conditions #\n",
    "cond_all = np.asarray([['SM','SC'],['OM', 'OC']])\n",
    "#cond_all = np.asarray([['SM', 'RE']]) # rest analysis\n",
    "\n",
    "# Create dir\n",
    "path = out_dir+sav_dir\n",
    "try: \n",
    "    os.mkdir(os.path.join(path))\n",
    "except OSError as error: \n",
    "    print(error)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-legislature",
   "metadata": {},
   "source": [
    "# GLM INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dynamic-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 1.5  # repetition time is 1 second\n",
    "n_scans = 205 # the acquisition comprises 204 scans\n",
    "# In seconds what is the lag between a stimulus onset and the peak bold response\n",
    "sec_lag = 0\n",
    "frame_times = np.arange(n_scans) * tr  # here are the correspoding frame times given TRs\n",
    "# sublist for individ analysis below # \n",
    "excl_sub_list = []\n",
    "# subject dics #\n",
    "group_sub_glm_a = {}\n",
    "group_sub_glm_b = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "warming-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD MASK # \n",
    "int_mask = nib.load('/jukebox/graziano/coolCatIsaac/ATM/data/work/workspace/load_fcma/mask_10r_n22-subs.nii.gz')\n",
    "gm_intmask = nib.load('/jukebox/graziano/coolCatIsaac/ATM/data/work/workspace/inter_allsubs_.01postresamp_MNI.nii')\n",
    "gm_shaef = nib.load('/jukebox/graziano/coolCatIsaac/ATM/data/work/workspace/shaef_gm_MNI_mask.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "convertible-earthquake",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../behavioral/n28_4_conds_ts_press_ovrlpREMOV.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0f8b909a37e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Bpress behavioral data -- overlap removed ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m bpress = dict(enumerate(np.load(os.path.join(load_bpress, \"n28_4_conds_ts_press_ovrlpREMOV.npy\"), \n\u001b[0;32m----> 3\u001b[0;31m                                 allow_pickle=True).flatten(),1))[1]\n\u001b[0m",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../behavioral/n28_4_conds_ts_press_ovrlpREMOV.npy'"
     ]
    }
   ],
   "source": [
    "## Bpress behavioral data -- overlap removed ##\n",
    "bpress = dict(enumerate(np.load(os.path.join(load_bpress, \"n28_4_conds_ts_press_ovrlpREMOV.npy\"), \n",
    "                                allow_pickle=True).flatten(),1))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "### runs to exclude with head motion accounted for and missing bpress runs deleted\n",
    "run_dic = dict(enumerate(np.load(os.path.join(confounds_dir, \"n28_runs_2_include_removNoBpress_delHMruns_threshp%s.npy\") %(hm_thresh), \n",
    "                                allow_pickle=True).flatten(),1))[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_sub = dict(enumerate(np.load(os.path.join(confounds_dir, 'n28_conf+cens_MERGE_removNoBpress_delHMruns_threshp%s_glm.npy')%(hm_thresh), \n",
    "                                          allow_pickle = True).flatten(),1))[1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-removal",
   "metadata": {},
   "source": [
    "# Set GLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "continent-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_glm = FirstLevelModel(t_r=1.5,\n",
    "                           signal_scaling=False,\n",
    "                           hrf_model = 'glover',\n",
    "                           drift_order=None,\n",
    "                           mask_img = gm_shaef,\n",
    "                           high_pass=None,\n",
    "                           drift_model=None,\n",
    "                           smoothing_fwhm=4,\n",
    "                           standardize=True,\n",
    "                           minimize_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "instructional-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drift_model': None,\n",
       " 'drift_order': None,\n",
       " 'fir_delays': [0],\n",
       " 'high_pass': None,\n",
       " 'hrf_model': 'glover',\n",
       " 'mask_img': <nibabel.nifti1.Nifti1Image at 0x7f460d28ee50>,\n",
       " 'memory': Memory(location=None),\n",
       " 'memory_level': 1,\n",
       " 'min_onset': -24,\n",
       " 'minimize_memory': False,\n",
       " 'n_jobs': 1,\n",
       " 'noise_model': 'ar1',\n",
       " 'signal_scaling': False,\n",
       " 'slice_time_ref': 0.0,\n",
       " 'smoothing_fwhm': 4,\n",
       " 'standardize': True,\n",
       " 'subject_label': None,\n",
       " 't_r': 1.5,\n",
       " 'target_affine': None,\n",
       " 'target_shape': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_glm.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-determination",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "lined-necklace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur conds: ['SM' 'RE'] at HM thresh 3\n",
      "design mat for sub-024\n",
      "returning SM RE\n",
      "fit glm\n"
     ]
    },
    {
     "ename": "UndefinedVariableError",
     "evalue": "name 'win1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/scope.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_resolvers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/collections/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# support subclasses that define __missing__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/collections/__init__.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'win1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/scope.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;31m# e.g., df[df > 0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'win1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mUndefinedVariableError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-833afce6cd68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# Compute three contrasts #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             sub_conts_b[win] = fmri_glm.compute_contrast(\n\u001b[0;32m---> 58\u001b[0;31m                     win+'-win0', output_type='effect_size') #effect_size\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mgroup_sub_glm_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msub_conts_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py\u001b[0m in \u001b[0;36mcompute_contrast\u001b[0;34m(self, contrast_def, stat_type, output_type)\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 con_vals[cidx] = expression_to_contrast_vector(\n\u001b[0;32m--> 589\u001b[0;31m                     con, design_columns)\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         valid_types = ['z_score', 'stat', 'p_value', 'effect_size',\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/nilearn/glm/contrasts.py\u001b[0m in \u001b[0;36mexpression_to_contrast_vector\u001b[0;34m(expression, design_columns)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontrast_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesign_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mcontrast_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"python\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontrast_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   3594\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resolvers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resolvers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3596\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    340\u001b[0m         )\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mparsed_expr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;31m# construct the engine and evaluate the parsed expression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, expr, engine, parser, env, level)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPARSERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0mParse\u001b[0m \u001b[0man\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \"\"\"\n\u001b[0;32m--> 817\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"visit_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit_Module\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSyntaxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"only a single expression is allowed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"visit_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit_Expr\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_rewrite_membership_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"visit_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit_BinOp\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_BinOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_transform_eq_ne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_downcast_constants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_evaluate_binop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36m_maybe_transform_eq_ne\u001b[0;34m(self, node, left, right)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_transform_eq_ne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mright\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"right\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"visit_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit_Name\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_NameConstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, env, side, encoding)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mtname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_TAG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDEFAULT_GLOBALS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/ops.py\u001b[0m in \u001b[0;36m_resolve_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resolve_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/base/envs/0.11.0/lib/python3.7/site-packages/pandas/core/computation/scope.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUndefinedVariableError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUndefinedVariableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mswapkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUndefinedVariableError\u001b[0m: name 'win1' is not defined"
     ]
    }
   ],
   "source": [
    "for cond_list in cond_all:\n",
    "    cond_a = cond_list[0]\n",
    "    cond_b = cond_list[1]\n",
    "    print('cur conds:', cond_list, 'at HM thresh', hm_thresh)\n",
    "    \n",
    "    for sub in sub_list:\n",
    "        # skip sub if both runs for a condition are unavailable (see head_mot)\n",
    "        if conf_sub[sub][cond_a] == [] or conf_sub[sub][cond_b] == []: continue\n",
    "        excl_sub_list.append(sub)\n",
    "        print('design mat for', sub)\n",
    "        \n",
    "        sub_conts_a = {}\n",
    "        sub_conts_b = {}\n",
    "        # Create events for all four runs\n",
    "        events_a,window_list = create_event_list(sub, bpress, cond_a,run_dic, base_onset,comp_onset_list,stim_dur)\n",
    "        # If rest condition, then use button presses from condition A \n",
    "        if cond_b == 'RE': \n",
    "            events_b,window_list = create_event_list_rest(sub, bpress, \"RE\",cond_a,run_dic,base_onset,comp_onset_list,stim_dur)\n",
    "        else:\n",
    "            events_b,window_list = create_event_list(sub, bpress, cond_b,run_dic,base_onset,comp_onset_list,stim_dur)\n",
    "            \n",
    "        # Create design matrix - SM\n",
    "        design_matrices_a = [make_first_level_design_matrix(frame_times, events_a[df], hrf_model = 'glover',\n",
    "                      drift_model=None, add_regs=conf_sub[sub][cond_a][df]) for df in events_a]\n",
    "        # Create design matrix - SC (df +1 cuz regs are index 1,2, not 0, 1)\n",
    "        design_matrices_b = [make_first_level_design_matrix(frame_times, events_b[df], hrf_model = 'glover',\n",
    "                      drift_model=None, add_regs=conf_sub[sub][cond_b][df]) for df in events_b]\n",
    "\n",
    "        # FMRI - high pass, low pass filter\n",
    "        cond_a_runs_temp, cond_b_runs_temp = load_2conds_runs_fmri(sub,behav_p,cond_a,cond_b,run_dic)\n",
    "        cond_a_runs = [nil.image.clean_img(unclean_img, detrend=False, \n",
    "                                        standardize=False, \n",
    "                                        low_pass=.1,high_pass=.01,t_r=1.5) for unclean_img in cond_a_runs_temp]\n",
    "        cond_b_runs = [nil.image.clean_img(unclean_img, detrend=False, \n",
    "                                        standardize=False, \n",
    "                                        low_pass=.1,high_pass=.01,t_r=1.5) for unclean_img in cond_b_runs_temp]\n",
    "        \n",
    "\n",
    "        # FIT GLM per subject \n",
    "        print('fit glm')\n",
    "        window_list = ['win1','win2','win3']\n",
    "        for win in window_list:\n",
    "            # group sub glm is now a nested dictionary with three contrasts\n",
    "            ## COND A ## \n",
    "            fmri_glm = fmri_glm.fit(cond_a_runs, design_matrices=design_matrices_a) \n",
    "            # Compute three contrasts #\n",
    "            sub_conts_a[win] = fmri_glm.compute_contrast(\n",
    "                    win+'-win0', output_type='effect_size') #effect_size\n",
    "            # each window saved as a key\n",
    "            group_sub_glm_a[sub] = sub_conts_a\n",
    "            ## Save ## \n",
    "            np.save(os.path.join(out_dir+sav_dir, '%s_%s.npy') %(cond_a, prefix), group_sub_glm_a)\n",
    "\n",
    "            ## COND B ## \n",
    "            fmri_glm = fmri_glm.fit(cond_b_runs, design_matrices=design_matrices_b) \n",
    "            # Compute three contrasts #\n",
    "            sub_conts_b[win] = fmri_glm.compute_contrast(\n",
    "                    win+'-win0', output_type='effect_size') #effect_size\n",
    "\n",
    "            group_sub_glm_b[sub] = sub_conts_b\n",
    "            ## Save ## \n",
    "            np.save(os.path.join(out_dir+sav_dir, '%s_%s.npy') %(cond_b,prefix), group_sub_glm_b)\n",
    "            \n",
    "            # Save INDIVIDUAL WITHIN CONTRASTS\n",
    "            nib.save(group_sub_glm_a[sub][win], os.path.join(out_dir+sav_dir, \n",
    "                                                            '%s_%s_%s_%s_zmap.nii') %(sub, cond_a, prefix1, win))\n",
    "            nib.save(group_sub_glm_b[sub][win], os.path.join(out_dir+sav_dir, \n",
    "                                                            '%s_%s_%s_%s_zmap.nii') %(sub, cond_b, prefix1, win))\n",
    "\n",
    "\n",
    "            # DOUBLE SUBTRACTION\n",
    "            full_contrast_win = math_img(\"img1 - img2\",img1=group_sub_glm_a[sub][win],img2=group_sub_glm_b[sub][win])\n",
    "\n",
    "            # save individual full contrast subtracted images for t-test\n",
    "            nib.save(full_contrast_win, os.path.join(\n",
    "                out_dir+sav_dir,'%s_%s_%s_%s_zmap.nii') % (sub,cond_a+'-'+cond_b, prefix, win))\n",
    "            \n",
    "            print('finish',win)\n",
    "        print('finish', sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-chorus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-burns",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
